{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TUD IS sentiment analysis tool\r\n",
    "This notebook can be used as a tool for  Sentiment Analysis of Tweets from Twitter with the Google Natural Language API about given keywords.\r\n",
    "## Preparations\r\n",
    "\r\n",
    "Installation of python requirements"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "!pip install searchtweets-v2 google-cloud-language==2.2.2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: searchtweets-v2 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: google-cloud-language==2.2.2 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-cloud-language==2.2.2) (2.0.1)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-cloud-language==2.2.2) (1.19.0)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-cloud-language==2.2.2) (21.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (2.0.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (51.3.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (1.53.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (3.17.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (2.26.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (1.40.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (0.2.8)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from packaging>=14.3->google-cloud-language==2.2.2) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-language==2.2.2) (1.26.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from searchtweets-v2) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\lukas\\.virtualenvs\\tud-is-sentiment-eogrpoki\\lib\\site-packages (from searchtweets-v2) (2.8.2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Lukas\\.virtualenvs\\tud-is-sentiment-eogrpOkI\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import os\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from google.cloud import language\r\n",
    "from google.auth import load_credentials_from_file\r\n",
    "from searchtweets import ResultStream, gen_request_parameters, load_credentials\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparations Google NLP-API\r\n",
    "To authenticate against the Google NLP-API an enviromentvariable `GOOGLE_APPLICATION_CREDENTIALS` pointing to a credentials file must be present in the executing environment.\r\n",
    "\r\n",
    "In addition the `analyze_text`-function uses a basic caching mechanism to save on API-Calls and network time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Instantiates a client\r\n",
    "nlp_client = language.LanguageServiceClient(credentials=load_credentials_from_file('./credentials/tud-is-sentiment.json')[0])\r\n",
    "\r\n",
    "\r\n",
    "def analyze_text(text, scope='document'):\r\n",
    "    document = language.Document(\r\n",
    "        content=text, type_=language.Document.Type.PLAIN_TEXT)\r\n",
    "    \r\n",
    "    f = nlp_client.analyze_entity_sentiment if scope == 'entity' else nlp_client.analyze_sentiment\r\n",
    "\r\n",
    "    analysis = f(request={'document': document})\r\n",
    "\r\n",
    "    return analysis\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparations for Twitter-API\r\n",
    "Tweets from twitter are fetched using the search-tweets library. To fetch tweets a `fetch-tweets`-function is defined that returns tweets for the query from a disk cache if possible.\r\n",
    "\r\n",
    "[https://github.com/twitterdev/search-tweets-python/tree/v2](https://github.com/twitterdev/search-tweets-python/tree/v2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "twitter_credentials_filename = \"./credentials/twitter-academic.yml\"\r\n",
    "\r\n",
    "search_args_all = load_credentials(\r\n",
    "    filename=twitter_credentials_filename,\r\n",
    "    yaml_key=\"search_all_tweets_v2\"\r\n",
    ")\r\n",
    "\r\n",
    "search_args_recent = load_credentials(\r\n",
    "    filename=twitter_credentials_filename,\r\n",
    "    yaml_key=\"search_recent_tweets_v2\"\r\n",
    ")\r\n",
    "\r\n",
    "cache_directory = 'cache'\r\n",
    "\r\n",
    "\r\n",
    "def fetch_tweets(search_term, credentials=search_args_all, max_results=100):\r\n",
    "    query = \"{} -is:retweet\".format(search_term)\r\n",
    "\r\n",
    "    cache_path = os.path.join('.', cache_directory, '{}.csv'.format(\r\n",
    "        ''.join(l for l in query if l not in [' ', ':'])\r\n",
    "    ))\r\n",
    "\r\n",
    "    os.makedirs(os.path.dirname(cache_path), exist_ok=True)\r\n",
    "\r\n",
    "    try:\r\n",
    "        df = pd.read_csv(cache_path)\r\n",
    "\r\n",
    "    except FileNotFoundError:\r\n",
    "        tweet_fields = [\r\n",
    "            'id',\r\n",
    "            'created_at',\r\n",
    "            'text',\r\n",
    "            'lang',\r\n",
    "            # 'entities',\r\n",
    "            'geo',\r\n",
    "            # 'public_metrics',\r\n",
    "            'source'\r\n",
    "        ]\r\n",
    "\r\n",
    "        rs = ResultStream(\r\n",
    "            request_parameters=gen_request_parameters(\r\n",
    "                query,\r\n",
    "                None,\r\n",
    "                results_per_call=100,\r\n",
    "                tweet_fields=','.join(tweet_fields)\r\n",
    "            ),\r\n",
    "            max_results=max_results,\r\n",
    "            **credentials\r\n",
    "        )\r\n",
    "\r\n",
    "        df = pd.DataFrame(\r\n",
    "\r\n",
    "            data=sum([page['data'] for page in rs.stream()], [])\r\n",
    "        )\r\n",
    "\r\n",
    "        df.to_csv(cache_path, index=False)\r\n",
    "\r\n",
    "    df = df.convert_dtypes()\r\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\r\n",
    "\r\n",
    "    return df\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "df = fetch_tweets('artificial intelligence')\r\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scientists Discover the Key to Artistic Succes...</td>\n",
       "      <td>en</td>\n",
       "      <td>1437807953231368200</td>\n",
       "      <td>2021-09-14 15:58:23+00:00</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scientists identify key conditions to set up a...</td>\n",
       "      <td>en</td>\n",
       "      <td>1437807867889868801</td>\n",
       "      <td>2021-09-14 15:58:03+00:00</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Join Pega's Head of Voice AI, Sabrina Atienza,...</td>\n",
       "      <td>en</td>\n",
       "      <td>1437807828220059649</td>\n",
       "      <td>2021-09-14 15:57:54+00:00</td>\n",
       "      <td>Dynamic Signal</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#AI caramba, those #neuralnetworks are power-h...</td>\n",
       "      <td>en</td>\n",
       "      <td>1437807774398746627</td>\n",
       "      <td>2021-09-14 15:57:41+00:00</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50% of recruiting programs reject anyone with ...</td>\n",
       "      <td>en</td>\n",
       "      <td>1437807530793635843</td>\n",
       "      <td>2021-09-14 15:56:43+00:00</td>\n",
       "      <td>Hootsuite Inc.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text lang  \\\n",
       "0  Scientists Discover the Key to Artistic Succes...   en   \n",
       "1  Scientists identify key conditions to set up a...   en   \n",
       "2  Join Pega's Head of Voice AI, Sabrina Atienza,...   en   \n",
       "3  #AI caramba, those #neuralnetworks are power-h...   en   \n",
       "4  50% of recruiting programs reject anyone with ...   en   \n",
       "\n",
       "                    id                created_at              source   geo  \n",
       "0  1437807953231368200 2021-09-14 15:58:23+00:00               IFTTT  <NA>  \n",
       "1  1437807867889868801 2021-09-14 15:58:03+00:00  Twitter for iPhone  <NA>  \n",
       "2  1437807828220059649 2021-09-14 15:57:54+00:00      Dynamic Signal  <NA>  \n",
       "3  1437807774398746627 2021-09-14 15:57:41+00:00     Twitter Web App  <NA>  \n",
       "4  1437807530793635843 2021-09-14 15:56:43+00:00      Hootsuite Inc.  <NA>  "
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "sentiment_df = df.groupby('lang').resample('H', on='created_at').agg({'text': '. '.join})\r\n",
    "ds = [analyze_text(row).document_sentiment for row in sentiment_df.text]\r\n",
    "scores, magnitudes = zip(*[(s.score, s.magnitude) for s in ds])\r\n",
    "\r\n",
    "sentiment_df['score'] = scores\r\n",
    "sentiment_df['magnitude'] = magnitudes\r\n",
    "\r\n",
    "sentiment_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>magnitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th>created_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ar</th>\n",
       "      <th>2021-09-14 14:00:00+00:00</th>\n",
       "      <td>@Latefoic كل ما له علاقة بال tech وال artifici...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <th>2021-09-14 14:00:00+00:00</th>\n",
       "      <td>#RaviVisvesvarayaSharadaPrasad  https://t.co/T...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">de</th>\n",
       "      <th>2021-09-14 14:00:00+00:00</th>\n",
       "      <td>Wie viele Artikel und Erwägungsgründe umfassen...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-14 15:00:00+00:00</th>\n",
       "      <td>Wer in #Datenpolitik mitreden will, sollte #DS...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <th>2021-09-14 13:00:00+00:00</th>\n",
       "      <td>https://t.co/rIP892urnF\n",
       "\n",
       "Play #FPL? Check this...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             text  \\\n",
       "lang created_at                                                                     \n",
       "ar   2021-09-14 14:00:00+00:00  @Latefoic كل ما له علاقة بال tech وال artifici...   \n",
       "da   2021-09-14 14:00:00+00:00  #RaviVisvesvarayaSharadaPrasad  https://t.co/T...   \n",
       "de   2021-09-14 14:00:00+00:00  Wie viele Artikel und Erwägungsgründe umfassen...   \n",
       "     2021-09-14 15:00:00+00:00  Wer in #Datenpolitik mitreden will, sollte #DS...   \n",
       "en   2021-09-14 13:00:00+00:00  https://t.co/rIP892urnF\n",
       "\n",
       "Play #FPL? Check this...   \n",
       "\n",
       "                                score  magnitude  \n",
       "lang created_at                                   \n",
       "ar   2021-09-14 14:00:00+00:00    0.0        0.0  \n",
       "da   2021-09-14 14:00:00+00:00    0.1        0.3  \n",
       "de   2021-09-14 14:00:00+00:00    0.2        0.7  \n",
       "     2021-09-14 15:00:00+00:00    0.4        1.6  \n",
       "en   2021-09-14 13:00:00+00:00    0.2        1.7  "
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tud-is-sentiment-eogrpOkI': pipenv)"
  },
  "interpreter": {
   "hash": "a34627970249a5cc7440a86baa7a266c59e2ac08413904645d42aec56580eb51"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}